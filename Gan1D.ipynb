{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gan1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CroZnccmgioL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/im-p/synteettinen_data/master/weight-height.csv?token=AJVZLUKXOOA3JTK7OE67OAK5QFEGM\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zetx75fTyDgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "\n",
        "def normal_distribution(r, f):\n",
        "  r_x_min = r.min()\n",
        "  r_x_max = r.max()\n",
        "  f_x_min = f.min()\n",
        "  f_x_max = f.max()\n",
        "\n",
        "  r_mean = r.mean()\n",
        "  r_std = r.std()\n",
        "  f_mean = f.mean()\n",
        "  f_std = f.std()\n",
        "  \n",
        "  r_x = np.linspace(r_x_min, r_x_max, 100)\n",
        "  f_x = np.linspace(f_x_min, f_x_max, 100)\n",
        "\n",
        "  r_y = scipy.stats.norm.pdf(r_x, r_mean, r_std)\n",
        "  f_y = scipy.stats.norm.pdf(f_x, f_mean, f_std)\n",
        "\n",
        "  plt.plot(r_x,r_y, color='coral', label = \"real\")\n",
        "  plt.plot(f_x,f_y, color='green', label = \"fake\")\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "\n",
        "  plt.title('Normal Distribution',fontsize=10, color=\"white\")\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW4vK6u-m3qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import hstack\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LeakyReLU\n",
        "\n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(n_inputs=2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(25,  kernel_initializer='he_uniform', input_dim=n_inputs))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dense(15,  kernel_initializer='he_uniform'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dense(10,  kernel_initializer='he_uniform'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dense(5,  kernel_initializer='he_uniform'))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, n_outputs=2):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
        "\tmodel.add(Dense(n_outputs, activation='linear'))\n",
        "\treturn model\n",
        " \n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(discriminator)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\treturn model\n",
        " \n",
        "# generate n real samples with class labels\n",
        "def generate_real_samples(n):\n",
        "\tX = df.Weight.values[:n*2].reshape(n,2)\n",
        "\ty = ones((n, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# evaluate the discriminator and plot real and fake points\n",
        "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
        "\t# prepare real samples\n",
        "\tx_real, y_real = generate_real_samples(n)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint(epoch, acc_real, acc_fake)\n",
        "\t# scatter plot real and fake data points\n",
        "\t#pyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
        "\t#pyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
        "\tnormal_distribution(x_real.flatten(),x_fake.flatten())\n",
        "\n",
        " \n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=256, n_eval=2000):\n",
        "\t# determine half the size of one batch, for updating the discriminator\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# prepare real samples\n",
        "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
        "\t\t# prepare fake examples\n",
        "\t\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator\n",
        "\t\td_model.train_on_batch(x_real, y_real)\n",
        "\t\td_model.train_on_batch(x_fake, y_fake)\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tx_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
        "\t\t# evaluate the model every n_eval epochs\n",
        "\t\tif (i+1) % n_eval == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, latent_dim)\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 5\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}